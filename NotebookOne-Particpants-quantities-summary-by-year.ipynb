{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three year summary Lake Geneva\n",
    "\n",
    "#### Notebook 1\n",
    "\n",
    "__Purpose:__ Present an analysis method for survey results from beach litter inventories on Lake Geneva.\n",
    "\n",
    "__Background:__ This is in the context of the global movement to reduce plastic debris in the maritime environment. Riverine inputs are major contributors of plastic debris (and all types of refuse) to the oceans. This is an analysis of the data collected on the shores of Lake Geneva over a three year period. The maritime protocol was modified in very specific ways to adjust for the local geography and population density.\n",
    "\n",
    "#### Research question: Is this a representative sample ?\n",
    "\n",
    "There is a push to quantify the amounts of plastic trash in the environment. It would be impossible to pick up every piece of trash in the environment and count it (that would solve the problem though). Extrapolating from economic and population data is one way to obtain a macro-view of the problem. But the margin of error on these type of calculations makes them unsuitable for identifying trends on a local or regional level.\n",
    "\n",
    "If sampling all the trash is not possibile, what if we sample as much as possible and see what that looks like? The following questions could be answered:\n",
    "\n",
    "1. What does the distribution of survey results look like?\n",
    "2. Do different groups of people produce different survey results?\n",
    "3. How different are the survey results from one location to another?\n",
    "4. What are the most abundant objects?\n",
    "5. How different are the survey results year over year?\n",
    "\n",
    "These series of notebooks will try to answer those questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "import collections\n",
    "# import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import geopandas\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import colors as mcolors\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.patches as mpatch\n",
    "from matplotlib.lines import Line2D\n",
    "from Utilities.utility_functions import *\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already in place\n"
     ]
    }
   ],
   "source": [
    "# The data is off of the API at https://mwshovel.pythonanywhere.com/dirt/api_home.html \n",
    "# You will have the opportunity to save the data locally\n",
    "# get some file structures in place\n",
    "\n",
    "# Required variables:\n",
    "folders = [\"Data\", \"Charts\", \"Utilities\"]\n",
    "here = os.getcwd()\n",
    "\n",
    "# check for existing and if not make folders\n",
    "check_for_folders(folders, here)\n",
    "\n",
    "# make a dictionary to call path by directory name\n",
    "my_folders = make_folders(folders, here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9af4a74fe4a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# get and put the data to local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mputTheDataToLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/three_year_final/Utilities/utility_functions.py\u001b[0m in \u001b[0;36mputTheDataToLocal\u001b[0;34m(end_points, here)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \"\"\"\n\u001b[1;32m     79\u001b[0m     \u001b[0mthe_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTheData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mwriteTheData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjsonFileGet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/three_year_final/Utilities/utility_functions.py\u001b[0m in \u001b[0;36mwriteTheData\u001b[0;34m(aDict, here)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moutPut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutPut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 2)"
     ]
    }
   ],
   "source": [
    "# save the data to local from the api\n",
    "\n",
    "# required variables:\n",
    "end_points = (\n",
    "    (\"beach_info\",\"http://mwshovel.pythonanywhere.com/dirt/beaches/Lac-L%C3%A9man/\"),\n",
    "    (\"all_data\", \"https://mwshovel.pythonanywhere.com/dirt/codes/Lac-L%C3%A9man/\")\n",
    ")\n",
    "# def checkForData():\n",
    "\n",
    "# get and put the data to local\n",
    "putTheDataToLocal(end_points, here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35afe03e7a87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# all the location information:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbeach_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonFileGet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_jsons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# make a data frame:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/three_year_final/Utilities/utility_functions.py\u001b[0m in \u001b[0;36mjsonFileGet\u001b[0;34m(this_path)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetIndexValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterNotebook/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Read the JSON data in from local\n",
    "# there is no need to hit the server a million times\n",
    "\n",
    "# required variables\n",
    "the_jsons = [\n",
    "    '/home/mw-shovel/three_year_final/Data/beach_info.json',\n",
    "    '/home/mw-shovel/three_year_final/Data/all_data.json'\n",
    "]\n",
    "\n",
    "# all the survey results by code, location, date, project:\n",
    "my_survey_results = jsonFileGet(the_jsons[1])\n",
    "def changeProjectName(aList, otherList, projectName):\n",
    "    aNewList = []   \n",
    "    for eachDict in aList:       \n",
    "        if eachDict[\"location_id\"] in otherList:\n",
    "            eachDict['project_id'] = projectName\n",
    "            aNewList.append(eachDict)\n",
    "        else:\n",
    "            aNewList.append(eachDict)\n",
    "    return aNewList\n",
    "            \n",
    "location_list = [\"Plage-de-St-Sulpice\", \"Parc-des-Pierrettes\",  \"Tiger-duck-beach\", \"Saint-Sulpice\"]\n",
    "project_name = \"tiger-duck\"\n",
    "my_survey_resultsx = changeProjectName(my_survey_results, location_list, project_name)\n",
    "\n",
    "# all the location information:\n",
    "beach_info = jsonFileGet(the_jsons[0])\n",
    "\n",
    "# make a data frame:\n",
    "the_survey_results = pd.DataFrame(my_survey_resultsx)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a pcs/m column:\n",
    "the_survey_results[\"pcs_m\"] = the_survey_results[\"quantity\"]/the_survey_results[\"length\"]\n",
    "\n",
    "# making a month, day and year column from a datetime object\n",
    "# makes sorting easier\n",
    "the_survey_results[\"py_date\"] = pd.to_datetime(the_survey_results[\"date\"])\n",
    "the_survey_results[\"py_month\"] = the_survey_results[\"py_date\"].dt.month\n",
    "the_survey_results[\"py_year\"] = the_survey_results[\"py_date\"].dt.year\n",
    "the_survey_results[\"py_day\"] = the_survey_results[\"py_date\"].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### one df for abundance and one df for density:\n",
    "abundance = the_survey_results[[\"project_id\", \"location_id\", \"date\",\"py_date\", \"py_month\", \"py_year\", \"code_id\", \"quantity\"]].copy()\n",
    "density = the_survey_results[[\"project_id\", \"location_id\", \"date\",\"py_date\", \"py_day\",\"py_month\", \"py_year\", \"code_id\", \"pcs_m\"]].copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_one_end_start = convertStringToDate([(\"2015-11-15\", \"2016-11-14\")])\n",
    "year_two_end_start = convertStringToDate([(\"2016-11-15\", \"2017-11-14\")])\n",
    "year_three_end_start=convertStringToDate([(\"2017-11-15\", \"2018-11-14\")])\n",
    "project_start_end = convertStringToDate([(\"2015-11-15\", \"2018-11-14\")])\n",
    "start_date = datetime.datetime.strptime(\"2015-11-15\", \"%Y-%m-%d\")\n",
    "end_date = datetime.datetime.strptime(\"2018-11-14\", \"%Y-%m-%d\")\n",
    "project_names = abundance.project_id.unique()\n",
    "def getAnnualSummaries(aList, aDf):\n",
    "    local = aDf.index.get_level_values('project_id')\n",
    "    projects = [x for x in aList if x in local]\n",
    "    out_put = {}\n",
    "    for name in projects:\n",
    "        the_df = aDf.loc[idx[name,:,:],:]\n",
    "        the_summary = the_df.describe()\n",
    "        the_total = the_df.quantity.sum()\n",
    "        the_dict = dict(\n",
    "            project=name,\n",
    "            data=the_df,\n",
    "            summary=the_summary,\n",
    "            the_total=the_total\n",
    "        )\n",
    "        out_put.update({name:the_dict})\n",
    "    combined = dict(\n",
    "        project='All',\n",
    "        data=aDf,\n",
    "        the_total=aDf.quantity.sum(),\n",
    "        summary=aDf.describe()\n",
    "    )\n",
    "    out_put.update({'All':combined})\n",
    "    return out_put"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Number of samples, sample locations, profile of participants...\n",
    "\n",
    "#### Samples grouped by participants\n",
    "\n",
    "There were/are many groups on the lake shore concerned by this problem. The data originates from five distinct groups:\n",
    "\n",
    "1. Students from École interantionale de Genève\n",
    "2. Students from The EPFL Solid waste engineering course\n",
    "3. Members of the World Wildlife Fund and or STOPPP\n",
    "4. Members of hammerdirt\n",
    "5. Members of Precious Collect Léman\n",
    "\n",
    "__How are the observations similar or different when sorted by group membership?__ The sampling method and conditions leave alot of responsibiliyt to the sampler. What a persons \"sees\" and how fatigue and environmental conditions effect an individuals attention to detail and motivation are variables that are part of the sampling process.\n",
    "\n",
    "Following a protocol and educating surveyors should minimise the effects of those variables. None the less the effects are real and they may have an impact on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = abundance[\n",
    "    (abundance.py_date >= start_date) & (abundance.py_date <= end_date)]\n",
    "daily_quantity = project_data[\n",
    "    [\"project_id\", \"location_id\",\"py_date\",\"quantity\"]].groupby(\n",
    "    [\"project_id\", \"location_id\",\"py_date\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data  Nov 2015 - Nov 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_summary = getAnnualSummaries(project_names,daily_quantity)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRows(aDf, rows):\n",
    "    the_dict = aDf.to_dict()[\"quantity\"]\n",
    "    the_keys = list(the_dict.keys())\n",
    "    for name in the_keys:\n",
    "        if name in rows.keys():\n",
    "            if name in [\"mean\", \"50%\", \"75%\", \"25%\"]:\n",
    "                val = np.round(the_dict[name], 2)\n",
    "                rows[name].append(val)\n",
    "            else:\n",
    "                val = int(the_dict[name])\n",
    "                rows[name].append(val)\n",
    "        else:\n",
    "            if name in [\"mean\", \"50%\", \"75%\", \"25%\"]:\n",
    "                val = np.round(the_dict[name], 2)\n",
    "                rows[name] = [val]\n",
    "            else:\n",
    "                val = int(the_dict[name])\n",
    "                rows[name] = [val]\n",
    "def getTotals(aDict, rows):\n",
    "    if \"total-pcs\" in rows.keys():\n",
    "        rows[\"total-pcs\"].append(aDict[\"the_total\"])\n",
    "    else:\n",
    "        rows[\"total-pcs\"] = [aDict[\"the_total\"]]\n",
    "def makeRows(aDict):\n",
    "    rows={}\n",
    "    header = list(aDict.keys())\n",
    "    for values in aDict:\n",
    "        getRows(aDict[values][\"summary\"], rows)\n",
    "        getTotals(aDict[values],rows)\n",
    "    return rows, header\n",
    "the_rows, header = makeRows(all_data_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def headerCell(label_s, label, header_bottom, ax):\n",
    "    header_cell = mpatch.Rectangle(\n",
    "            (label_s,header_bottom),\n",
    "            .18, .1, alpha=1, facecolor=\"royalblue\", edgecolor= \"royalblue\")\n",
    "    rx, ry = header_cell.get_xy()\n",
    "    cx = rx + header_cell.get_width()/2.0\n",
    "    cy = ry + header_cell.get_height()/2.0\n",
    "    ax.add_patch(header_cell)\n",
    "    ax.annotate(label, (cx, cy), color='w', weight='bold', \n",
    "            fontsize=12, ha='center', va='center')\n",
    "def tableCell(label_s, label, row_height, faceColor, edgeColor, fontColor, fontWeight, alpha, ax):\n",
    "    table_cell = mpatch.Rectangle(\n",
    "        (label_s,row_height),\n",
    "        .18, .1, alpha=1, facecolor=faceColor, edgecolor=edgeColor)\n",
    "    rx, ry = table_cell.get_xy()\n",
    "    cx = rx + table_cell.get_width()/2.0\n",
    "    cy = ry + table_cell.get_height()/2.0\n",
    "    ax.add_patch(table_cell)\n",
    "    ax.annotate(label, (cx, cy), color=fontColor, weight=fontWeight, \n",
    "            fontsize=12, ha='center', va='center')\n",
    "def rowHeader(label_s, label, row_height,faceColor, edgeColor, alpha, ax):\n",
    "    table_cell = mpatch.Rectangle(\n",
    "        (label_s,row_height),\n",
    "        .12, .1, alpha=1, facecolor=faceColor, edgecolor= edgeColor)\n",
    "    rx, ry = table_cell.get_xy()\n",
    "    cx = rx + table_cell.get_width()/2.0\n",
    "    cy = ry + table_cell.get_height()/2.0\n",
    "    ax.add_patch(table_cell)\n",
    "    ax.annotate(label, (cx, cy), color='b', weight='normal', \n",
    "            fontsize=12, ha='right', va='center')  \n",
    "\n",
    "def makeTable(header, the_rows, header_bottom):\n",
    "    fig = plt.figure(figsize=(8.5,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    header_bottom=.88\n",
    "    cell_width = .18\n",
    "    for i,label in enumerate(header):\n",
    "        if i == 0:\n",
    "            label_start = .1\n",
    "            headerCell(label_start, label,header_bottom, ax)\n",
    "        else:\n",
    "            label_start = .1 + (i*.18)\n",
    "            headerCell(label_start, label,header_bottom, ax)\n",
    "    for k,x in enumerate(the_rows):\n",
    "        cell_height=.095\n",
    "        label_start = .1\n",
    "        cell_width = .18\n",
    "        if k == 0:\n",
    "            row_height = header_bottom-cell_height        \n",
    "            for j,value in enumerate(the_rows[x]):\n",
    "                if j == 0:                \n",
    "                    label_start = .1\n",
    "                    tableCell(\n",
    "                        label_start,\n",
    "                        value,\n",
    "                        row_height,\n",
    "                        \"none\",\n",
    "                        \"royalblue\",\n",
    "                        \"royalblue\",\n",
    "                        \"normal\",\n",
    "                        1, ax)\n",
    "\n",
    "                else:\n",
    "                    label_start = .1 + (j*cell_width)\n",
    "                    tableCell(\n",
    "                        label_start,\n",
    "                        value,\n",
    "                        row_height,\n",
    "                        \"none\",\n",
    "                        \"royalblue\",\n",
    "                        \"royalblue\",\n",
    "                        \"normal\",\n",
    "                        1, ax)\n",
    "        else:\n",
    "            row_height = header_bottom-cell_height-(cell_height*k)\n",
    "            if k%2 != 0:        \n",
    "                for j,value in enumerate(the_rows[x]):\n",
    "                    if j == 0:\n",
    "                        label_start = .1\n",
    "                        tableCell(\n",
    "                            label_start,\n",
    "                            value,\n",
    "                            row_height,\n",
    "                            \"royalblue\",\n",
    "                            \"royalblue\",\n",
    "                            \"white\",\n",
    "                            \"normal\",\n",
    "                            1, ax\n",
    "                        )\n",
    "                    else:\n",
    "                        label_start = .1 + (j*cell_width)\n",
    "                        tableCell(\n",
    "                            label_start,\n",
    "                            value,\n",
    "                            row_height,\n",
    "                            \"royalblue\",\n",
    "                            \"royalblue\",\n",
    "                            \"white\",\n",
    "                            \"normal\",\n",
    "                            1, ax\n",
    "                        )\n",
    "            else:\n",
    "                for j,value in enumerate(the_rows[x]):\n",
    "                    if j == 0:\n",
    "                        label_start = .1\n",
    "                        tableCell(\n",
    "                            label_start,\n",
    "                            value,\n",
    "                            row_height,\n",
    "                            \"none\",\n",
    "                            \"royalblue\",\n",
    "                            \"royalblue\",\n",
    "                            \"normal\",\n",
    "                            1, ax\n",
    "                        )\n",
    "                    else:\n",
    "                        label_start = .1 + (j*cell_width)\n",
    "                        tableCell(\n",
    "                            label_start,\n",
    "                            value,\n",
    "                            row_height,\n",
    "                            \"none\",\n",
    "                            \"royalblue\",\n",
    "                            \"royalblue\",\n",
    "                            \"normal\",\n",
    "                            1, ax\n",
    "                        )\n",
    "    for n,x in enumerate(list(the_rows.keys())):\n",
    "        label_start = .01\n",
    "        cell_height=.095\n",
    "        if n == 0:\n",
    "            row_height = header_bottom-cell_height  \n",
    "            rowHeader(label_start, x, row_height,\"none\", \"none\", 1, ax)   \n",
    "        else:\n",
    "            row_height = header_bottom-cell_height-(cell_height*n)\n",
    "            rowHeader(label_start, x,row_height, \"none\", \"none\", 1, ax) \n",
    "\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "makeTable(header, the_rows, .88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year one Nov 2015 - Nov 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_one_data = daily_quantity.loc[idx[:,:,year_one_end_start[0][0]:year_one_end_start[0][1]], :]\n",
    "projct_names = list(year_one_data.index.get_level_values(0))\n",
    "all_data_summary = getAnnualSummaries(project_names,year_one_data)\n",
    "the_rows, header = makeRows(all_data_summary)\n",
    "makeTable(header, the_rows, .88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year two Nov 2016 - Nov 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_two_data = daily_quantity.loc[idx[:,:,year_two_end_start[0][0]:year_two_end_start[0][1]], :]\n",
    "projct_names = list(year_two_data.index.get_level_values(0))\n",
    "all_data_summary = getAnnualSummaries(project_names,year_two_data)\n",
    "the_rows, header = makeRows(all_data_summary)\n",
    "makeTable(header, the_rows, .88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year three Nov 2017 - Nov 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_three_data = daily_quantity.loc[idx[:,:,year_three_end_start[0][0]:year_three_end_start[0][1]], :]\n",
    "projct_names = list(year_three_data.index.get_level_values(0))\n",
    "all_data_summary = getAnnualSummaries(project_names,year_three_data)\n",
    "the_rows, header = makeRows(all_data_summary)\n",
    "makeTable(header, the_rows, .88)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
